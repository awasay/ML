{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy import stats\n",
    "from sknn.mlp import Classifier, Layer\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import time\n",
    "\n",
    "def get_accuracy(prediction,actual):\n",
    "    assert(len(prediction)==len(actual))\n",
    "    \n",
    "    correct = 1.0*np.count_nonzero(prediction==actual)\n",
    "    total = 1.0*(len(prediction))\n",
    "    \n",
    "    print \"The accuracy is: \"+str(correct/total)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train=pd.read_excel(r'H:\\Harvard ML\\practice 2\\SCfeatures_train.xlsx')\n",
    "#t_train=X_train['t_train']\n",
    "#X_train=X_train.drop('t_train',1)\n",
    "#X_test=pd.read_csv(r'H:\\Harvard ML\\practice 2\\SCfeatures_test.csv')\n",
    "#X_test=X_test[X_train.columns]\n",
    "\n",
    "X_train=pd.read_csv(r'C:\\Users\\Yohann\\Documents\\Machine Learning\\practical2\\X_train.csv')\n",
    "t_train=pd.read_csv(r'C:\\Users\\Yohann\\Documents\\Machine Learning\\practical2\\t_train.csv')\n",
    "train_ids=pd.read_csv(r'C:\\Users\\Yohann\\Documents\\Machine Learning\\practical2\\train_ids.csv')\n",
    "X_test=pd.read_csv(r'C:\\Users\\Yohann\\Documents\\Machine Learning\\practical2\\X_test.csv')\n",
    "t_test=pd.read_csv(r'C:\\Users\\Yohann\\Documents\\Machine Learning\\practical2\\t_test.csv')\n",
    "test_ids=pd.read_csv(r'C:\\Users\\Yohann\\Documents\\Machine Learning\\practical2\\test_ids.csv')\n",
    "\n",
    "#t_train must be a list of integers not labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3086, 119)\n",
      "(3724, 119)\n",
      "(3086, 1)\n",
      "(3724, 1)\n",
      "(3724, 1)\n",
      "(3086, 1)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print t_train.shape\n",
    "print t_test.shape\n",
    "print train_ids.shape\n",
    "print test_ids.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160L,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t_train70.as_matrix().reshape(len(t_train70),)\n",
    "t_train70.as_matrix().reshape(len(t_train70),).shape\n",
    "#X_train70.as_matrix().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare validation set\n",
    "X_train70, X_train30, t_train70, t_train30 = train_test_split(X_train, t_train, test_size=0.3)\n",
    "n_targets=t_train.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.718142548596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7181425485961123"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X_train70, t_train70.as_matrix().reshape(len(t_train70),))\n",
    "prediction_log = logreg.predict(X_train30)\n",
    "\n",
    "get_accuracy(prediction_log,t_train30.as_matrix().reshape(len(t_train30),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### TEST WITH AND WITHOUT DUMMIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-033049e4ddf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     n_iter=20)\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train70\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train70\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#prediction_nn=nn.predict(X_train30)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;31m# Now train based on a problem transformed into regression.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training on dataset of {:,} samples with {:,} total size.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.pyc\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;34m\"This neural network has already been initialized.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_specs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.pyc\u001b[0m in \u001b[0;36m_create_specs\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[1;34m\"Mismatch between dataset size and units in output layer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[0;32m    730\u001b[0m                          \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "#from sknn.platform import cpu32, thread16\n",
    "from sknn.mlp import Classifier, Layer\n",
    "start_time = time.time()\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\",warning=None, units=50),\n",
    "        #Layer(\"Sigmoid\",warning=None, units=200),\n",
    "        #Layer(\"Sigmoid\",warning=None, units=200),\n",
    "        #Layer(\"Sigmoid\",warning=None, units=200),\n",
    "        Layer(\"Softmax\",warning=None, units=n_targets)],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=20)\n",
    "nn.fit(X_train70.as_matrix(), t_train70.as_matrix().reshape(len(t_train70),))\n",
    "\n",
    "#prediction_nn=nn.predict(X_train30)\n",
    "             \n",
    "#prediction_nn=prediction_nn.reshape(len(X_train30),) \n",
    "\n",
    "#print(\"--- %s seconds ---\" % round((time.time() - start_time),1))                         \n",
    "\n",
    "#get_accuracy(prediction_nn,t_train30.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_predictions(test_ids,prediction):\n",
    "    assert(len(prediction)==len(test_ids))\n",
    "    \n",
    "    writer = csv.writer(open(r'H:\\Harvard ML\\practice 2\\predictionNN.csv','wb'))\n",
    "    \n",
    "    writer.writerow([\"Id\",\"Prediction\"])\n",
    "    for i in range(0,len(test_ids)):\n",
    "        writer.writerow([test_ids[i],prediction[i]])\n",
    "\n",
    "write_predictions(test_ids,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier Classifier(batch_size=1, callback=None, debug=False, dropout_rate=None,\n",
      "      f_stable=0.001,\n",
      "      hidden0=<sknn.nn.Layer `Sigmoid`: units=100, name=u'hidden0', frozen=False>,\n",
      "      layers=[<sknn.nn.Layer `Sigmoid`: units=100, name=u'hidden0', frozen=False>, <sknn.nn.Layer `Softmax`: units=15, name=u'output', frozen=False>],\n",
      "      learning_momentum=0.9, learning_rate=0.001, learning_rule=u'sgd',\n",
      "      loss_type=None, n_iter=50, n_stable=10,\n",
      "      output=<sknn.nn.Layer `Softmax`: units=15, name=u'output', frozen=False>,\n",
      "      random_state=None, regularize=None, valid_set=None, valid_size=0.0,\n",
      "      verbose=None, warning=None, weight_decay=None, weights=None):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.03      0.05        30\n",
      "          1       0.67      0.33      0.44        12\n",
      "          2       1.00      0.31      0.47        13\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.11      0.20         9\n",
      "          5       1.00      0.50      0.67        14\n",
      "          6       1.00      0.47      0.64        17\n",
      "          7       0.00      0.00      0.00        12\n",
      "          8       0.84      0.94      0.89       472\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       0.82      1.00      0.90       178\n",
      "         11       1.00      0.56      0.71         9\n",
      "         12       0.75      0.86      0.80       110\n",
      "         13       0.00      0.00      0.00        18\n",
      "         14       0.44      0.58      0.50        12\n",
      "\n",
      "avg / total       0.76      0.81      0.77       926\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  1   1   0   0   0   0   0   0  17   0   8   0   2   0   1]\n",
      " [  1   4   0   0   0   0   0   0   3   0   0   0   3   1   0]\n",
      " [  0   0   4   0   0   0   0   0   5   0   3   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3   0   3   1   3]\n",
      " [  0   0   0   0   1   0   0   0   6   0   1   0   1   0   0]\n",
      " [  1   0   0   0   0   7   0   0   4   0   1   0   0   0   1]\n",
      " [  0   0   0   0   0   0   8   0   0   0   9   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  10   0   0   0   2   0   0]\n",
      " [  4   1   0   0   0   0   0   0 442   0   9   0  15   1   0]\n",
      " [  1   0   0   0   0   0   0   0   6   0   0   0   3   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 178   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3   5   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0  13   0   0   0  95   0   2]\n",
      " [  0   0   0   0   0   0   0   0  15   0   0   0   2   0   1]\n",
      " [  0   0   0   0   0   0   0   0   3   0   2   0   0   0   7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\" % (nn, classification_report(t_train30.values, prediction_nn)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(t_train30.values, prediction_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "rs = RandomizedSearchCV(nn, param_distributions={\n",
    "    'learning_rate': stats.uniform(0.001, 0.05),\n",
    "    'hidden0__units': stats.randint(4, 12),\n",
    "    'hidden0__type': [\"Rectifier\", \"Sigmoid\", \"Tanh\"]})\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "rs.best_estimator_\n",
    "\n",
    "prediction_rs=rs.predict(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EXRT(X_train,t_train,x,t,predict):\n",
    "\n",
    "\tclf = ExtraTreesClassifier(n_estimators=500, max_depth=None)\n",
    "\tclf.fit(X_train70, t_train70)\n",
    "\tprediction = clf.predict(X_train30)\n",
    "\n",
    "\tif predict:\n",
    "\t\twrite_predictions(t,prediction)\n",
    "\telse:\n",
    "\t\tget_accuracy(prediction,t)\n",
    "\n",
    "For prediction (will result in a prediction file)\n",
    " \n",
    "models.EXRT(X_train,t_train,X_test,test_ids,True)\n",
    " \n",
    "For cross-validation (will print accuracy)\n",
    " \n",
    "models.EXRT(X_train,t_train,X_valid,t_valid,False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
